{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Python R code analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>Parsing and beautifing data</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from statsmodels.robust.scale import mad\n",
    "from matplotlib import ticker\n",
    "from FieldClassificationType import FieldClassificationType\n",
    "from Multivalue import Multivalue\n",
    "from Policies import Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we create an utils class/file ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmptyStrings(df: pd.DataFrame) -> None:\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "\n",
    "def get_field_metadata(field_name:str, classification_metadata: dict[str, dict[str, str]]) -> dict[str, str]:\n",
    "    return classification_metadata[field_name]\n",
    "\n",
    "def process_splitted_values(values: pd.Series, multiple: str):\n",
    "    if (multiple):\n",
    "        return values.apply(lambda x: [item.strip() for item in re.split(rf'\\{Multivalue.SEPARATOR.value}', x)])\n",
    "\n",
    "    return values.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project data objects will not be in JSON files. They will be accessible directly from the relis application environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/relis_classification_rsc_CV.json', 'r', encoding='utf8') as f:\n",
    "   classification_data: list[dict[str, str]] =  json.loads(f.read())\n",
    "\n",
    "with open('../data/relis_classification_rsc_metadata_CV.json', 'r', encoding='utf8') as f:\n",
    "   classification_metadata: dict[str, dict[str, str]] =  json.loads(f.read())\n",
    "\n",
    "print(classification_data)\n",
    "print(classification_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split config file based on data type\n",
    "def filter_row_by_field_type(paper, field_type):\n",
    "    pd_row = {key: value[\"value\"] for key, value in paper.items() if value['type'] == field_type}\n",
    "    return pd_row\n",
    "\n",
    "nominal_df = pd.DataFrame([filter_row_by_field_type(paper, FieldClassificationType.NOMINAL.value) for paper in classification_data])\n",
    "continuous_df = pd.DataFrame([filter_row_by_field_type(paper, FieldClassificationType.CONTINUOUS.value) for paper in classification_data])\n",
    "\n",
    "# For test purpose ?\n",
    "if (Policies.DROPNA.value):\n",
    "    removeEmptyStrings(nominal_df)\n",
    "    removeEmptyStrings(continuous_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>DESCRIPTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation. <br>\n",
    "Currently, I'll proceed by deleting them in the begining of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_desc(field_name: str, data: pd.DataFrame):\n",
    "    # Get metadata\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "    # Split the values by the \"|\" character and flatten the result\n",
    "    split_values = process_splitted_values(data[field_name], field_metadata['multiple'])\n",
    "    flattened_values = np.concatenate(split_values)\n",
    "\n",
    "    # Generate the frequency table\n",
    "    freq_table = pd.Series(flattened_values, dtype=str).value_counts().reset_index()\n",
    "    freq_table.columns = ['value', 'n']\n",
    "\n",
    "    # Calculate the percentage\n",
    "    freq_table['percentage'] = (freq_table['n'] / freq_table['n'].sum()) * 100\n",
    "\n",
    "    return freq_table\n",
    "\n",
    "\n",
    "desc_distr_vector = {field_name: beautify_data_desc(field_name, nominal_df) for field_name in nominal_df.columns}\n",
    "print(desc_distr_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_plot(field_name: str, data: pd.DataFrame):\n",
    "    df = beautify_data_desc(field_name, data)\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        return\n",
    "\n",
    "    # Set the theme\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    barplot = sns.barplot(data=df, x=\"value\", y=\"percentage\", hue=\"n\")\n",
    "\n",
    "    # Get metadata\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "\n",
    "    # Set labels and title\n",
    "    title = f\"{field_metadata['title']} ~ Bar plot\"\n",
    "    barplot.set_title(title)\n",
    "    barplot.set_xlabel(field_metadata['title'])\n",
    "    barplot.set_ylabel(\"Percentage\")\n",
    "\n",
    "    return barplot.figure\n",
    "\n",
    "bar_plot_vector = {field_name: generate_bar_plot(field_name, nominal_df) for field_name in nominal_df.columns}\n",
    "print(desc_distr_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Statistics\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statistics(field_name: str, data: pd.DataFrame):\n",
    "    series =  data[field_name]\n",
    "    # Should be removed if we always drop na initially.\n",
    "    series.replace('', np.nan, inplace=True)\n",
    "    \n",
    "    if (len(data) == 0):\n",
    "        return\n",
    "\n",
    "    nan_policy = 'omit' if Policies.DROPNA.value else 'propagate'\n",
    "    results = {\n",
    "    \"vars\": 1,  # Since it's for a single variable\n",
    "    \"n\": series.count(),\n",
    "    \"mean\": series.mean(),\n",
    "    \"sd\": series.std(),\n",
    "    \"median\": series.median(),\n",
    "    \"trimmed\": series[series.between(series.quantile(0.25), series.quantile(0.75))].mean(),\n",
    "    \"mad\": mad(series),  # Mean absolute deviation\n",
    "    \"min\": series.min(),\n",
    "    \"max\": series.max(),\n",
    "    \"range\": series.max() - series.min(),\n",
    "    \"skew\": skew(series, nan_policy=nan_policy),\n",
    "    \"kurtosis\": kurtosis(series, nan_policy=nan_policy, fisher=True),\n",
    "    \"se\": series.std() / np.sqrt(series.count())  \n",
    "    }\n",
    "    return results\n",
    "\n",
    "statistics_vector = {field_name: generate_statistics(field_name, continuous_df) for field_name in continuous_df.columns}\n",
    "print(statistics_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Box Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "\n",
    "    # Create the box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=series, color='lightblue')\n",
    "\n",
    "    # Overlay the mean point\n",
    "    mean_value = series.mean()\n",
    "    plt.scatter(x=0, y=mean_value, color='red', s=50, zorder=3)  # s is the size of the point\n",
    "\n",
    "    # Set the title and labels\n",
    "    title = f\"{field_metadata['title']} ~ Box plot\"\n",
    "    plt.title(title)\n",
    "    plt.ylabel(field_metadata['title'])\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.0f'))\n",
    "\n",
    "    return plt\n",
    "\n",
    "box_plot_vector = {field_name: generate_box_plot(field_name, continuous_df) for field_name in continuous_df.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Violin Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_violin_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "    \n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(data=series, color=\"lightgray\")\n",
    "\n",
    "    plt.title(f\"{field_metadata['title']} ~ Violin plot\")\n",
    "    plt.ylabel(field_metadata['title'])\n",
    "    plt.xlabel(\"Density\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    return plt\n",
    "\n",
    "violin_plot_vector = {field_name: generate_violin_plot(field_name, continuous_df) for field_name in continuous_df.columns}\n",
    "print(violin_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>EVOLUTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Publication.year a classfication field which is mandatory for each of the project ? <br>\n",
    "It's currently hard coded and doesn't follow any patern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_evo(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "    \n",
    "    # Create new DataFrame with specified columns\n",
    "    subset_data = pd.DataFrame({\n",
    "        'Year': publication_year,\n",
    "        'Value': process_splitted_values(series, field_metadata['multiple'])\n",
    "    })\n",
    "    \n",
    "    subset_data = subset_data.explode('Value')\n",
    "\n",
    "    # Remove rows with empty values\n",
    "    subset_data = subset_data[(subset_data['Value'] != '')]\n",
    "\n",
    "    subset_data = subset_data.groupby(['Year', 'Value']).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "\n",
    "def expand_data(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    subset_data = beautify_data_evo(field_name, publication_year, data)\n",
    "\n",
    "    # Pivoting the data\n",
    "    subset_data = subset_data.pivot(index='Year', columns='Value', values='Frequency').fillna(0)\n",
    "\n",
    "    subset_data.columns.name = None\n",
    "    subset_data.reset_index(inplace=True)\n",
    "\n",
    "    return subset_data \n",
    "\n",
    "violin_plot_vector = {field_name: expand_data(field_name, continuous_df[\"publication_year\"], nominal_df)\n",
    "                       for field_name in nominal_df.columns}\n",
    "print(violin_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Evolution Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evo_plot(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    subset_data = beautify_data_evo(field_name, publication_year, data)\n",
    "\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=subset_data, x='Year', y='Frequency', hue='Value', style='Value', markers=True)\n",
    "\n",
    "    # Setting title, labels, and theme\n",
    "    plt.title(f\"{field_metadata['title']} ~ Evolution plot\")\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "evolution_plot_vector = {field_name: generate_evo_plot(field_name, continuous_df[\"publication_year\"], nominal_df)\n",
    "                          for field_name in nominal_df.columns}\n",
    "print(evolution_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>COMPARATIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_comp(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "    dependency_field_metadata = get_field_metadata(dependency_field_name, classification_metadata)\n",
    "    \n",
    "    # # Selecting the required columns\n",
    "    subset_data = pd.DataFrame({\n",
    "        field_name: data[field_name],\n",
    "        dependency_field_name: data[dependency_field_name]\n",
    "    })\n",
    "    \n",
    "    # Filtering out rows where any of the variables is empty\n",
    "    subset_data = subset_data[(subset_data[field_name] != \"\") & (subset_data[dependency_field_name] != \"\")]\n",
    "\n",
    "    # Splitting the strings and expanding into separate rows\n",
    "    subset_data[field_name] = process_splitted_values(subset_data[field_name], field_metadata['multiple'])\n",
    "    subset_data = subset_data.explode(field_name)\n",
    "\n",
    "    subset_data[dependency_field_name] = process_splitted_values(subset_data[dependency_field_name],\n",
    "                                                                  dependency_field_metadata['multiple'])\n",
    "    subset_data = subset_data.explode(dependency_field_name)\n",
    "\n",
    "    # Counting occurrences\n",
    "    subset_data = subset_data.groupby([field_name, dependency_field_name]).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data\n",
    "\n",
    "def evaluate_comparative_dependency_field(field_name: str, data: pd.DataFrame, strategy):\n",
    "    \"\"\"\n",
    "    Perform a statistical analysis strategy for each \n",
    "    dependency field of a given classification field.\n",
    "    Act as a wrapper for the comparative statistical\n",
    "    functions\n",
    "    \"\"\"\n",
    "    field_names = list(data.columns)\n",
    "\n",
    "    return {dependency_field_name: strategy(field_name, dependency_field_name, data)\n",
    "             for dependency_field_name in field_names if dependency_field_name != field_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Frequency Tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plot_vector = {field_name: evaluate_comparative_dependency_field(field_name, nominal_df, beautify_data_comp)\n",
    "                       for field_name in nominal_df.columns}\n",
    "\n",
    "print(violin_plot_vector[\"domain\"][\"transformation_language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stacked_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "    dependency_field_metadata = get_field_metadata(dependency_field_name, classification_metadata)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=field_name, y='Frequency', hue=dependency_field_name, data=subset_data)\n",
    "\n",
    "    plt.title(f\"{field_metadata['title']} and {dependency_field_metadata['title']} ~ Stacked bar plot\")\n",
    "    plt.xlabel(field_metadata['title'])\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    return plt\n",
    "\n",
    "stacked_bar_plot_vector = {field_name: evaluate_comparative_dependency_field(field_name, nominal_df, generate_stacked_bar_plot)\n",
    "                       for field_name in nominal_df.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Grouped Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grouped_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    field_metadata = get_field_metadata(field_name, classification_metadata)\n",
    "    dependency_field_metadata = get_field_metadata(dependency_field_name, classification_metadata)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=field_name, y='Frequency', hue=dependency_field_name, data=subset_data, dodge=True)\n",
    "\n",
    "    plt.title(f\"{field_metadata['title']} and {dependency_field_metadata['title']} ~ Stacked bar plot\")\n",
    "    plt.xlabel(field_metadata['title'])\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    return plt\n",
    "\n",
    "grouped_bar_plot_vector = {field_name: evaluate_comparative_dependency_field(field_name, nominal_df, generate_grouped_bar_plot)\n",
    "                       for field_name in nominal_df.columns}\n",
    "\n",
    "print(grouped_bar_plot_vector[\"domain\"][\"transformation_language\"].show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
